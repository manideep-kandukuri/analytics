{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "pd.pandas.set_option('display.max_columns',None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('fifa.csv')\n",
    "var_info = pd.read_csv('fifa_+variable_information.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# column: 'Value'\n",
    "Details:\n",
    "    Amount with Euro symbol as prefix and suffix ‘K’ or ‘M’ indicating thousands and millions respectively.\n",
    "    \n",
    "    \n",
    "Required output:\n",
    "        Convert to Float after getting rid of currency symbol and suffix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Value'] = dataset['Value'].apply(lambda x : x.split(',')[0][1:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_conversion(x):\n",
    "    if(x[-1]=='M'):\n",
    "        return float(x[0:-1])*1000000\n",
    "    elif(x[-1]=='K'):\n",
    "        return float(x[0:-1])*1000\n",
    "    else:\n",
    "        return float(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Value'] = dataset['Value'].map(value_conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Value'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Value'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# column: ''Wage''\n",
    "Details:\n",
    "    Amount with Euro symbol as prefix and suffix ‘K’ or ‘M’ indicating thousands and millions respectively.\n",
    "    \n",
    "    \n",
    "Required output:\n",
    "        Convert to Float after getting rid of currency symbol and suffix.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Wage'] = dataset['Wage'].apply(lambda x : x.split(',')[0][1:]) \n",
    "dataset['Wage'] = dataset['Wage'].map(value_conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Wage'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# column: 'Joined'\n",
    "Details: Year as a string, in some cases complete date as string\n",
    "\n",
    "Required output: Convert to int with only year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "dataset['Joined'] = pd.DatetimeIndex(dataset['Joined']).year\n",
    "dataset['Joined'] = dataset['Joined'].fillna(dataset['Joined'].mean()).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset[dataset['Joined'].isnull()]['Joined'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# column: 'Contract Valid Until'\n",
    "Details: Date as a string \n",
    "\n",
    "Required output: Convert to datetime type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Contract Valid Until'] = pd.to_datetime(dataset['Contract Valid Until'])\n",
    "dataset['Contract Valid Until'] = pd.to_datetime(dataset['Contract Valid Until'],format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# column: ''Height''\n",
    "Details: In inches with a quotation mark  \n",
    "\n",
    "Required output :Convert to Float with decimal points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Height'] = dataset['Height'].str.replace(\"'\",'.',regex=False)\n",
    "dataset['Height'] = dataset['Height'].astype('float64')\n",
    "dataset['Height'] = dataset['Height'].fillna(dataset['Height'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# column: 'Weight'\n",
    "Details: Contains the suffix lbs\n",
    "\n",
    "Required output :Remove the suffix and convert to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Weight'] = dataset['Weight'].str.replace(\"lbs\",'',regex=False)\n",
    "dataset['Weight'] = dataset['Weight'].astype('float64')\n",
    "dataset['Weight'] = dataset['Weight'].fillna(dataset['Weight'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# column: 'Release Clause'\n",
    "Details: Amount with Euro symbol as prefix and suffix ‘K’ or ‘M’ indicating thousands and millions respectively\n",
    "\n",
    "Required output :Convert to Float after getting rid of currency symbol and suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Release Clause'] = dataset['Release Clause'].fillna('E0')\n",
    "dataset['Release Clause']=dataset['Release Clause'].apply(lambda x : x[1:])\n",
    "dataset['Release Clause'] = dataset['Release Clause'].map(value_conversion)\n",
    "dataset['Release Clause'] = dataset['Release Clause'].replace(0,np.nan)\n",
    "dataset['Release Clause']= dataset['Release Clause'].fillna(dataset['Release Clause'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.\tCheck for missing values and do a mean imputation where necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_with_nan = [feature for feature in dataset.columns if dataset[feature].isnull().sum()>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features_with_nan:\n",
    "    print('{} missing values are ==========>>>{}'.format(feature,np.round(dataset[feature].isnull().mean(),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [feature for feature in dataset.columns if dataset[feature].dtype != 'O']\n",
    "numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Loaned From'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since Loaned From contains many(almose 90%) null values ..we can remove the column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns='Loaned From',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[['Overall','Potential']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since the dataset contains same values for both the columns overall and potential we can delete any one of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.drop(columns=['Potential'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[dataset['Name'].duplicated()]['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the name column has duplicates..there are players with same name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset['Flag'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Body Type'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#photo,flag and club logo,Jersey Number columns can be deleted because we have the details like id,name,nationality and club name to represent them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=['Photo','Flag','Club Logo','Jersey Number'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now for numerical columns we replace the null values with mean\n",
    "#if there are any outliers then we replace with median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [feature for feature in dataset.columns if dataset[feature].dtype != 'O']\n",
    "for feature in numerical_features:\n",
    "    dataset[feature] = dataset[feature].fillna(dataset[feature].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after applying mean to fill nulls..now checking the null values for numerical_columns:\n",
    "for feature in numerical_features:\n",
    "    print(dataset[feature].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now checking the null values for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features=[feature for feature in dataset.columns if dataset[feature].dtypes=='O']\n",
    "for feature in categorical_features:\n",
    "    print('{} => missing values are {}'.format(feature,dataset[feature].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are replacing these null values with \"missing\" string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in categorical_features:\n",
    "    dataset[feature] = dataset[feature].fillna('missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now our data is complete.all null values are treated.\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('cleaned_minipro.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA PART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.\tPlot the distribution of Overall rating for all players. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm,skew\n",
    "sns.distplot(dataset['Overall'])\n",
    "plt.axvline(dataset['Overall'].mean(),label = 'mean',color = 'red')\n",
    "plt.axvline(dataset['Overall'].median(),label = 'median',color = 'blue')\n",
    "plt.axvline(dataset['Overall'].mode()[0],label = 'mode',color = 'green') # ---> here we get series for mode hence using [0] to get value\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can clearly see the Potential is almost normal(evenly distributed)\n",
    "#the mean and median is around 67\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.\tGenerate pair plots for the following variables:\n",
    "Overall, Value, Wage, International Reputation, Height, Weight, Release Clause\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pplot_features = dataset[['Overall','Wage','International Reputation','Height','Weight','Release Clause']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pplot_features.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(pplot_features.corr())\n",
    "plt.show()\n",
    "#fig = sns.pairplot(pplot_features.corr()).get_figure()\n",
    "\n",
    "#sns.pairplot(pplot_features.corr()).savefig('pairplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(wage -overall),(international reputation-overall),(release clause - overall) ===>> these have a positive correlation\n",
    "#(wage-internaltional repuation),(release clause-wage)==> has a positive correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.\tGenerate a table containing the top 20 players ranked by Overall score and whose contract expires in 2020.\n",
    "    a)\tWhat would the average wage for this set of players be?\n",
    "    b)\tWhat is the average age?\n",
    "    c)\tIs there a correlation between the Overall rating and Value for these players?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = dataset[dataset['Contract Valid Until'].dt.year == 2020]\n",
    "#dataset1['Overall_dense_rank'] = dataset1['Overall'].rank(method='dense',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_table = dataset1.sort_values(by='Overall',ascending=False)[:20]\n",
    "print('The average wage of required players is :',req_table['Wage'].mean())\n",
    "print('The average age of required players is :',req_table['Age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(dataset1[['Overall','Value']].corr(),annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yes,there is a positive correlation between the overall rating and value of the player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.\tGenerate tables containing the top 5 players by Overall rating for each unique position.\n",
    "    a)\tAre there any players appearing in more than one Table. Please point out such players.\n",
    "    b)\tWhat is the average wage one can expect to pay for the top 5 in every position?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_features = dataset['Position'].unique()\n",
    "position_features\n",
    "position_features1=position_features\n",
    "print(position_features1)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(position_features)):\n",
    "    position_features1[i] = dataset[dataset['Position'] == position_features[i]].sort_values('Overall',ascending =False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat(position_features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[result.duplicated(subset=['ID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are no players who appeared more than once in top 5 as per their positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_wage_for_position = result.groupby('Position')['Wage'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_wage_for_position = pd.DataFrame(avg_wage_for_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg_wage_for_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_wage_for_position.drop('missing',axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_wage_for_position.sort_values(by='Wage',ascending=False).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The average wages as per position is plotted using bar graph\n",
    "#ST position has the highest avg wage\n",
    "#LWB position has the lowest avg.wage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
